---
layout: post
title: 排序算法小结
category: blog
description: 包含了一些常用的排序算法的基本思想和时间复杂度，同时也有一些自己的想法

tags:
- sort
- algorithm
---



## 比较排序

这篇Post主要是感觉通过找工同学的反馈，感觉排序算法在笔试和面试中还是比较重要的，另外，之前对这些算法只是有了笼统的认识，还没有比较系统的去接触，所以正好借着这些机会去再系统的接触一下，好建立起一个良好的认识。

所谓比较排序，就是，在排序的结果中，各元素的次序是基于输入元素间的比较而得到的。例如插入排序、归并排序（合并排序）、堆排序、快速排序等。

### 插入排序

插入排序最直接的实例就是扑克牌，手中的牌都是已经排好序的，每次抽到的牌都要从一端开始比较，例如，从小端，则当出现比当前牌大的，则当前牌就应该放在该位置。

算法流程：
	
	INSERTION_SORT(A)
		for j :  2 to length(A)
			do 	key = A[j]
				insert A[j] into the sorted sequence A[1..j-1]
				i = j - 1
				while i>0 and A[i]>key
				do	A[i+1] = A[i]
					i = i - 1
				A[i+1] = key

与插入排序类似的排序算法还有选择排序和冒泡排序。这两种方法的思想是一致的，即都是通过每次的遍历选出当前序列中的极值，并放置在相应的位置上，不同的是两者产生极值的方式不同，选择排序是通过和极值位上的数值进行比较并交换，而冒泡排序则是通过相邻两个位置的数值比较和交换一步一步的更新到极值位置。
	
插入排序和选择排序，冒泡排序都是比较直观的排序算法，一般都是生活中常见的排序方法的抽象版，而且算法的复杂度都是`O(n^2)`。

另有[希尔排序](http://zh.wikipedia.org/wiki/%E5%B8%8C%E5%B0%94%E6%8E%92%E5%BA%8F)与插入排序类似，区别主要在于每次比较前进的步长不同，根据步长的不同，算法的时间复杂度不等，最优复杂度为`O(n (log n)^2)`。
	
### 归并（合并）排序
	
归并排序的排序思想是建立在递归分治之上的，即将现有的序列分为两段，分别对各段进行排序，然后将两段有序队列合并为一个有序队列。这个操作过程是递归的，直至到最后序列只有两个元素，按需对两个元素进行交换。
	
算法流程：

	MERGE-SORT(A, p, r)
		if p < r
			then 
				q = floor((p+r)/2)
				MERGE-SORT(A, p, q)
				MERGE-SORT(A, q+1, r)
				MERGE(A, p, q, r)
	
其中MERGE-SORT为递归调用，而MERGE为合并操作。关于合并操作，其实比较常用的是将两个子有序列的头元素进行比较，选择较大（或者较小）的元素取出，然后更新头元素指针，做同样的操作，这样可以保证当前取到的元素一定是这两个序列中最大（或者最小）的。
					
由于归并排序的递归特性，其时间复杂度可以用递推式的形式表达，其中设n为序列的元素个数，T(n)为长度为n的序列进行归并排序的时间复杂度。

>	当n=1时，T(n) = O(1)

>	当n>1时，T(n) = 2T(n/2)+O(n)

其中，当n>1时，前一项为对半分的两个子归并排序的时间代价，后一项的O(n)为合并过程的时间代价。最终可以得到归并排序的时间复杂度为`O(n log n)`。

这里有个小例子，是算法导论上的一道思考题，如何用归并排序的算法结构求出一个序列中的逆序对？这个小例子可以加深对比较排序的具体理解。关于这个的解答，我认为应该是，在合并的过程中，每当从后一个序列中取出头元素时，就将前一个序列所剩的元素数累加起来，因为这时，不论前一个序列中还剩什么样的元素，他们都与当前取出的这个元素成逆序对。

### 堆排序

这里要先引入一个`原地排序`的概念：在任何时候，序列中只有常数个元素存储在输入数组以外，则称为原地排序。其实，顾名思义，就是不需要额外的存储空间，只通过原序列中的交换就可以完成排序。

堆排序中使用了堆这样一个数据结构，关于堆，其实是一棵[完全二叉树](http://zh.wikipedia.org/zh-cn/%E4%BA%8C%E5%8F%89%E6%A0%91)，它有一个特性，对于`大根堆`来说，**其每个分叉处都满足父节点的值大于子节点**，`小根堆`类似。

这里简单记一下完全二叉树的存储方法，由于完全二叉树的特性，使得其可以存在一位数组里，并且下标特点如下：如果当前节点为i，则其父节点的下标为floor(i/2)，其左子节点下标为2i，右子节点下标为2i+1。

对于堆来说，有两个基本的操作，一个是建堆，一个是调整堆。建堆相当与堆的初始化，而调整堆，则是在堆出现元素增加和减少时为了保持堆特性所需要做的一些操作。

以大根堆为例，建堆和调整的流程：

	BUILD-MAX-HEAP(A)
		heap-size[A] = length[A]
		for i : floor(length[A]/2) downto 1 do
			MAX-HEAPIFY(A, i)
		
	MAX-HEAPIFY(A, i)
		l = LEFT(i)
		r = RIGHT(i)
		if l <= heap-size[A] and A[l] > A[i]
			then largest = l
			else largest = i
		if r <= heap-size[A] and A[r] > A[largest]
			then largest = r
		if largest != i
			then 
				exchange A[i]<>A[largest]
				MAX-HEAPIFY(A, largest)

从伪代码可以看出，其实建堆的过程就是一个不断调整堆的过程，这里有一点要注意一下，就是BUILD-MAX-HEAP中的循环是从floor(length[A]/2)开始的，这是完全二叉树的特性之一，floor(length[A]/2)是这个二叉树最下面的一个内节点，floor(length[A]/2)+1就是第一个叶节点。而调整堆的话只需要从最底层的父节点开始就可以，因为叶节点没有子节点，没有调整的必要。另一个原因是，要想要保证上层根节点可以正确更新，则需要下层的根节点首先更新。

在调整堆的MAX-HEAPIFY过程中，要做的其实只有一点就是保持堆中**根大于子节点**的这一特性，所以，在三个值中选择一个较大的并将较大的值的位置存起来最后与根所在位置的值进行交换已更新根，如果某个子节点大于根节点，则交换完后需要更新以该子节点为根的子树，即调用MAX-HEAPIFY(A, largest)，这样可以保证每次上层的更新能及时传递到下层。

可以看到，在大根堆的例子中，最终的根上的值是这棵树中最大的值（小根堆类似），所以，堆排序利用的正是这个特点，每次取出堆顶元素，然后重新调整堆产生新的堆顶元素，如此往复直到所有元素都取完，堆排序的流程为：

	HEAPSORT(A)
		BUILD-MAX-HEAP(A)
		for i : length[A] downto 2 do
			exchange A[1]<>A[i]
			heap-size[A] = heap-size[A] - 1
			MAX-HEAPIFY(A, 1)
			
用heap-size限定了堆的范围，从而分割了未排序和已排序的部分。	

HEAPSORT的时间代价是`O(n log n)`，其中，BUILD-MAX-HEAP的时间复杂度为`O(n)`，MAX-HEAPIFY的时间复杂度为`O(log n)`。
		
#### 优先队列

`优先队列`是一中用来维护由一组元素构成的集合S的数据结构，这种数据结构的特点是有一个可以进行排序的key值，而且只关心key值中的极值。典型的应用场景为操作系统中的调度，每次都需要将优先级最高元素的拿出来调度，而不关心其他元素。

### 快速排序

快速排序是现在应用很广的排序算法，各种库中的排序算法基本都是实现的快速排序。快排也是一种原地排序，不需要太多的额外空间，同时是一种比较排序，最后它的思想也是基于递归分治。

快速排序的关键在每次对序列的划分是否平衡，即是否能选择合适的值将序列尽可能的平分成两个自序列，当然如果合适值的选取代价太大也不可取，而现实中这个“合适的值”往往是随意取的，例如当前序列的头元素，亦或是一个随机位置上的元素。

一个样例的划分流程如下：

	PARTITION(A, p, r)
		x = A[r]
		i = p -1
		for j : p to r - 1 do
			if A[j] <= x
			then
				i = i + 1
				exchange A[i]<>A[j]
		exchange A[i+1]<>A[r]
	return i+1

这个过程最后返回的是中间的分割点，这个点把序列分成了两个自序列。然后这个分割点的确定是在选取了序列最后一个元素作为主元（pivot element）后，将小于等于它的放在它前面，大于它的放在它后面，从而分成了两个自序列。伪代码中的i是用来标记最左边的一个大于主元的元素的位置，当在这个元素的右边找到有小于主元的元素，就交换这两个元素值。

快排的完成实现流程是：

	QUICKSORT(A, p, r)
		if p < r
		then
			q = PARTITION(A, p, r)
			QUICKSORT(A, p, q-1)
			QUICKSORT(A, q+1, r)

结构很清晰，在PARTITION确定了分割点后递归对自序列进行排序，这里和归并排序的区别在与，这里在对子序列进行排序前就已经将元素的区域划分在PARTITION中做好了，不用在后续进行合并了。

#### 时间复杂度

- 最坏情况：每次划分的自序列都是分别包含n-1和1和元素，T(n) = T(n-1) + T(0) + O(n) = T(n-1) + O(n) => T(n) = O(n^2)
- 最佳情况：每次划分都能平分当前序列，T(n) <= 2T(n/2) + O(n) => T(n) = O(n log n)

首先，明确一点，快排的平均复杂度是趋向于最佳复杂度的，可能是因为在PARTITION中**任何**一种按常数比例的划分都会产生深度为O(log n)的递归树，其中每一层的代价为O(n)，所以总的运行时间都是O(n log n)，具体的原因应该是要涉及到了概率方面的推导。
			
### 比较排序的算法时间下界

比较排序可以抽象成一颗决策树，而这棵决策树的每个节点都是序列中两个元素的比较，从一个高的角度来看，这些比较的顺序可以是任意的，因为无论任何两个元素比较其产生的效果都是把接下来可能出现的情况一分为二，而比较排序中也主要依靠比较来不断的缩小正确序列的范围，抽象出来也就类似与决策树，一种信息上的不断二分，最终确定。

[![decision tree](http://kang-da.tk/images/post/comparision-sort-decision-tree.png)](http://kang-da.tk/images/post/comparision-sort-decision-tree.png)

对于一个有n个元素的序列，设其对应的决策树高为h，可达的叶节点数为l。其可能产生的排列有n!个，决策数至少有n!个叶节点，即n！<= l，同时决策树是一棵完全二叉树，其叶节点不多于2^h，即l<=2^h。即可得到n! <= 2^h ==> h >= log (n!) = O(n log n) ([Stirling's approximation](http://en.wikipedia.org/wiki/Stirling%27s_approximation))。决策树高决定了排序算法的比较次数，而对于比较排序而言，比较次数决定了其时间复杂度。所以，可以得出结论，**比较排序的最坏运行时间的下界为`O(n log n)`**。

另外，再引入一个概念，最佳上界能够与上段所得到的非平凡下界渐近地相等，则这个排序算法是`渐近最优`的，归并排序和堆排序都是渐近最优的，而快速排序不是，因为它的最坏时间复杂度是O(n^2)。

## 非比较排序

与比较排序相对比，这类排序算法不依赖与元素的比较，所以笼统的称为非比较排序，其实它们的另一个特点是都是`线性时间`的排序，即时间复杂度是`O(n)`级别的，但是这些排序算法往往尤其局限性，需要数据满足某些特性。

### 计数排序

### 基数排序

### 桶排序
